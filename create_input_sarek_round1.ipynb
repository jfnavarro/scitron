{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Parse Excel Exomes\n",
    "meta = pd.read_excel(\"Metadata.xlsx\")\n",
    "\n",
    "# Parse Excel PDXs\n",
    "metapdxs = pd.read_excel('Metadata_pdx.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gender to XX or XY\n",
    "meta.loc[meta[\"Gender\"] == \"female\", \"Gender\"] = \"XX\"\n",
    "meta.loc[meta[\"Gender\"] == \"male\", \"Gender\"] = \"XY\"\n",
    "\n",
    "# Convert sample id to string\n",
    "meta['Sample_ID'] = meta['Sample_ID'].astype(str)\n",
    "\n",
    "# Remove dots from sample names\n",
    "meta['Sample_ID'] = meta['Sample_ID'].str.replace('.', '')\n",
    "\n",
    "# Make sample id unique\n",
    "meta['Sample_ID'] = ['{}_{}_{}'.format(x, i, meta.iloc[i,:]['sampletype']) for i,x in enumerate(meta['Sample_ID'])]\n",
    "\n",
    "# Create lane column\n",
    "meta['lane'] = 1\n",
    "\n",
    "# Check for re-sequenced sampless\n",
    "rows_to_add = list()\n",
    "for index, row in meta.iterrows():\n",
    "    if not pd.isnull(row['FASTA ID (re-secuenciado) ']):\n",
    "        new_row = row.copy()\n",
    "        new_row['FASTA ID'] = row['FASTA ID (re-secuenciado) ']\n",
    "        new_row['lane'] = 2\n",
    "        rows_to_add.append(new_row)\n",
    "for r in rows_to_add:\n",
    "    meta = meta.append(r, ignore_index=True)\n",
    "\n",
    "\n",
    "# Check the files are in S3 and adjust incorrect names if they are not found\n",
    "filenames = set()\n",
    "s3 = boto3.client('s3')\n",
    "for obj in s3.list_objects_v2(Bucket='scitron', Prefix='exomes/')['Contents'][1:]:\n",
    "    filenames.add(os.path.basename(obj['Key']))\n",
    "for index, row in meta.iterrows():\n",
    "    if not pd.isnull(row['FASTA ID']) and row['FASTA ID'] != '':\n",
    "        file_id = str(row['FASTA ID']).strip()\n",
    "        meta.loc[index, 'FASTA ID'] = 's3://scitron/exomes/{}_1.fastq.gz'.format(file_id)\n",
    "        meta.loc[index, 'FASTA2'] = 's3://scitron/exomes/{}_2.fastq.gz'.format(file_id)\n",
    "        file1 = os.path.basename(meta.loc[index, 'FASTA ID'])\n",
    "        file2 = os.path.basename(meta.loc[index, 'FASTA2'])\n",
    "        if file1 not in filenames or file2 not in filenames:\n",
    "            meta.loc[index, 'FASTA ID'] = meta.loc[index, 'FASTA ID'].replace('_1.fastq.gz', '_R1_001.fastq.gz')\n",
    "            meta.loc[index, 'FASTA2'] = meta.loc[index, 'FASTA2'].replace('_2.fastq.gz', '_R2_001.fastq.gz')\n",
    "\n",
    "# Add PDXs information\n",
    "for index, row in metapdxs.iterrows():\n",
    "    file_id = row['FastaID'].replace('/', '-')\n",
    "    patiend_id = row['Pt VHIO ID']\n",
    "    sample_type = row['Type of sample']\n",
    "    sample_id = \"{}_{}\".format(row['PDX_UBOP_ID'], sample_type)\n",
    "    lane = 1\n",
    "    for file in filenames:\n",
    "        if 'R2' not in file and file_id in file:\n",
    "            new_row = meta.loc[meta[\"Patient ID\"] == patiend_id].iloc[0].copy()\n",
    "            new_row['lane'] = lane\n",
    "            lane += 1\n",
    "            new_row['sampletype'] = sample_type\n",
    "            new_row['Sample_ID'] = sample_id\n",
    "            new_row['FASTA ID'] = 's3://scitron/exomes/{}'.format(file)\n",
    "            new_row['FASTA2'] = 's3://scitron/exomes/{}'.format(file.replace('R1', 'R2'))\n",
    "            meta = meta.append(new_row, ignore_index=True)\n",
    "\n",
    "# Discard Missing samples\n",
    "meta = meta.loc[meta['FASTA ID'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md5sum.txt\n"
     ]
    }
   ],
   "source": [
    "# Final check \n",
    "filenames = set()\n",
    "files1 = set()\n",
    "files2 = set()\n",
    "s3 = boto3.client('s3')\n",
    "for obj in s3.list_objects_v2(Bucket='scitron', Prefix='exomes/')['Contents'][1:]:\n",
    "    filenames.add(os.path.basename(obj['Key']))\n",
    "for index, row in meta.iterrows():\n",
    "    file1 = os.path.basename(str(row['FASTA ID']))\n",
    "    files1.add(file1)\n",
    "    file2 = os.path.basename(str(row['FASTA2']))\n",
    "    files2.add(file2)\n",
    "    if file1 not in filenames or file2 not in filenames:\n",
    "        print(\"Row {} does not have the correct file names {} {}\".format(index, file1, file2))\n",
    "\n",
    "for diff in sorted((filenames - (files1 | files2))):\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarek format\n",
    "sub_meta = meta.loc[:,[\"Patient ID\", \"Gender\", \"sampletype\", \"Sample_ID\", \"lane\", \"FASTA ID\", \"FASTA2\"]]\n",
    "\n",
    "# Convert sample type to 0 (normal) and 1 (tumor)\n",
    "sub_meta.loc[sub_meta[\"sampletype\"] == \"gDNA\", \"sampletype\"] = 0\n",
    "sub_meta.loc[sub_meta[\"sampletype\"] != 0, \"sampletype\"] = 1\n",
    "\n",
    "# Test dataset\n",
    "sub_meta.loc[sub_meta[\"Patient ID\"] == \"VHIO_13\"].to_csv(\"testsamples.tsv\", \n",
    "                                                         sep=\"\\t\", \n",
    "                                                         header=None, \n",
    "                                                         index=None)\n",
    "# All samples\n",
    "sub_meta.to_csv(\"samples.tsv\", sep=\"\\t\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
